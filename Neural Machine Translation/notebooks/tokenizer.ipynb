{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# English to Marathi Neural Machine Translation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Tokenizer & Dataset Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = pd.read_csv(\"samantar_dataset.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>src</th>\n",
                            "      <th>tgt</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Political suggestions</td>\n",
                            "      <td>राजकीय पक्षांच्या सूचना</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>He said this in a public meeting.</td>\n",
                            "      <td>यावेळी सभेत बोलताना त्यांनी ही घोषणा केली.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Few close friends and family members attended ...</td>\n",
                            "      <td>तसेच त्यांच्या लग्नासोहळ्यासाठी काही नातेवाईक ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Supreme Court closes a contempt plea filed by ...</td>\n",
                            "      <td>‘चौकीदार चोर है’ या राहुल गांधी याच्या वक्तव्य...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>The growth of our economy depends on PSBs abil...</td>\n",
                            "      <td>सार्वजनिक क्षेत्रातील बँकांची बाजारात वित्त पु...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 src  \\\n",
                            "0                              Political suggestions   \n",
                            "1                  He said this in a public meeting.   \n",
                            "2  Few close friends and family members attended ...   \n",
                            "3  Supreme Court closes a contempt plea filed by ...   \n",
                            "4  The growth of our economy depends on PSBs abil...   \n",
                            "\n",
                            "                                                 tgt  \n",
                            "0                            राजकीय पक्षांच्या सूचना  \n",
                            "1         यावेळी सभेत बोलताना त्यांनी ही घोषणा केली.  \n",
                            "2  तसेच त्यांच्या लग्नासोहळ्यासाठी काही नातेवाईक ...  \n",
                            "3  ‘चौकीदार चोर है’ या राहुल गांधी याच्या वक्तव्य...  \n",
                            "4  सार्वजनिक क्षेत्रातील बँकांची बाजारात वित्त पु...  "
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sentencepiece as spm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(\"smp_input.txt\", \"w\", encoding=\"utf-8\") as f:\n",
                "    for en, mr in zip(dataset[\"src\"], dataset[\"tgt\"]):\n",
                "        f.write(en.strip() + \"\\n\")\n",
                "        f.write(mr.strip() + \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
                        "trainer_spec {\n",
                        "  input: smp_input.txt\n",
                        "  input_format: \n",
                        "  model_prefix: en_mr_unigram\n",
                        "  model_type: UNIGRAM\n",
                        "  vocab_size: 32000\n",
                        "  self_test_sample_size: 0\n",
                        "  character_coverage: 0.9995\n",
                        "  input_sentence_size: 0\n",
                        "  shuffle_input_sentence: 1\n",
                        "  seed_sentencepiece_size: 1000000\n",
                        "  shrinking_factor: 0.75\n",
                        "  max_sentence_length: 4192\n",
                        "  num_threads: 16\n",
                        "  num_sub_iterations: 2\n",
                        "  max_sentencepiece_length: 16\n",
                        "  split_by_unicode_script: 1\n",
                        "  split_by_number: 1\n",
                        "  split_by_whitespace: 1\n",
                        "  split_digits: 0\n",
                        "  pretokenization_delimiter: \n",
                        "  treat_whitespace_as_suffix: 0\n",
                        "  allow_whitespace_only_pieces: 0\n",
                        "  required_chars: \n",
                        "  byte_fallback: 0\n",
                        "  vocabulary_output_piece_score: 1\n",
                        "  train_extremely_large_corpus: 0\n",
                        "  seed_sentencepieces_file: \n",
                        "  hard_vocab_limit: 1\n",
                        "  use_all_vocab: 0\n",
                        "  unk_id: 1\n",
                        "  bos_id: 2\n",
                        "  eos_id: 3\n",
                        "  pad_id: 0\n",
                        "  unk_piece: <unk>\n",
                        "  bos_piece: <s>\n",
                        "  eos_piece: </s>\n",
                        "  pad_piece: <pad>\n",
                        "  unk_surface:  ⁇ \n",
                        "  enable_differential_privacy: 0\n",
                        "  differential_privacy_noise_level: 0\n",
                        "  differential_privacy_clipping_threshold: 0\n",
                        "}\n",
                        "normalizer_spec {\n",
                        "  name: nmt_nfkc\n",
                        "  add_dummy_prefix: 1\n",
                        "  remove_extra_whitespaces: 1\n",
                        "  escape_whitespaces: 1\n",
                        "  normalization_rule_tsv: \n",
                        "}\n",
                        "denormalizer_spec {}\n",
                        "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
                        "trainer_interface.cc(186) LOG(INFO) Loading corpus: smp_input.txt\n",
                        "trainer_interface.cc(411) LOG(INFO) Loaded all 358108 sentences\n",
                        "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
                        "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
                        "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
                        "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
                        "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
                        "trainer_interface.cc(541) LOG(INFO) all chars count=24025083\n",
                        "trainer_interface.cc(552) LOG(INFO) Done: 99.9509% characters are covered.\n",
                        "trainer_interface.cc(562) LOG(INFO) Alphabet size=146\n",
                        "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999509\n",
                        "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 358108 sentences.\n",
                        "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
                        "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=12376909\n",
                        "unigram_model_trainer.cc(312) LOG(INFO) Initialized 461127 seed sentencepieces\n",
                        "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 358108\n",
                        "trainer_interface.cc(611) LOG(INFO) Done! 307273\n",
                        "unigram_model_trainer.cc(602) LOG(INFO) Using 307273 sentences for EM training\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=152215 obj=12.9253 num_tokens=617180 num_tokens/piece=4.05466\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=130237 obj=10.5387 num_tokens=618776 num_tokens/piece=4.75115\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=97648 obj=10.5287 num_tokens=647471 num_tokens/piece=6.63066\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=97493 obj=10.5054 num_tokens=647549 num_tokens/piece=6.64201\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=73118 obj=10.5967 num_tokens=689366 num_tokens/piece=9.42813\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=73112 obj=10.5751 num_tokens=689518 num_tokens/piece=9.43098\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=54832 obj=10.7089 num_tokens=738563 num_tokens/piece=13.4696\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=54831 obj=10.6837 num_tokens=738522 num_tokens/piece=13.4691\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=41123 obj=10.8631 num_tokens=790987 num_tokens/piece=19.2347\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=41123 obj=10.8295 num_tokens=790933 num_tokens/piece=19.2333\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=35200 obj=10.9417 num_tokens=819096 num_tokens/piece=23.2698\n",
                        "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=35199 obj=10.9239 num_tokens=819085 num_tokens/piece=23.2701\n",
                        "trainer_interface.cc(689) LOG(INFO) Saving model: en_mr_unigram.model\n",
                        "trainer_interface.cc(701) LOG(INFO) Saving vocabs: en_mr_unigram.vocab\n"
                    ]
                }
            ],
            "source": [
                "import sentencepiece as spm\n",
                "\n",
                "spm.SentencePieceTrainer.train(\n",
                "    input=\"smp_input.txt\",\n",
                "    model_prefix=\"en_mr_unigram\",\n",
                "    vocab_size=32000,                 # recommended\n",
                "    model_type=\"unigram\",             # important\n",
                "    character_coverage=0.9995,        # important for Marathi\n",
                "    pad_id=0,\n",
                "    unk_id=1,\n",
                "    bos_id=2,\n",
                "    eos_id=3\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "sp = spm.SentencePieceProcessor()\n",
                "sp.load(\"en_mr_unigram.model\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[24075, 1184, 2935, 5, 1399, 4686, 3754, 11607, 16264, 71, 340, 2098, 546, 2627, 3588, 1451, 3644, 5, 9903, 44, 8870, 35, 366, 10159, 9241, 4152, 9416, 70, 92, 4]\n",
                        "वृत्तसंस्थेने दिलेल्या माहितीनुसार, विरोध करण्याऱ्या शेतकऱ्यांची दिशाभूल केली जात असल्याचा आरोप प्रगतीशील शेतकरी संघटना, सेनीपतचे अध्यक्ष कंवलसिंग चौहान यांनी केला.\n"
                    ]
                }
            ],
            "source": [
                "tokens = sp.encode(\"वृत्तसंस्थेने दिलेल्या माहितीनुसार, विरोध करण्याऱ्या शेतकऱ्यांची दिशाभूल केली जात असल्याचा आरोप प्रगतीशील शेतकरी संघटना, सेनीपतचे अध्यक्ष कंवलसिंग चौहान यांनी केला.\", out_type=int)\n",
                "print(tokens)\n",
                "text = sp.decode(tokens)\n",
                "print(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<pad>\t0\n",
                        "\n",
                        "<unk>\t0\n",
                        "\n",
                        "<s>\t0\n",
                        "\n",
                        "</s>\t0\n",
                        "\n",
                        ".\t-2.78317\n",
                        "\n",
                        ",\t-3.64751\n",
                        "\n",
                        "▁the\t-3.87328\n",
                        "\n",
                        "▁of\t-4.58389\n",
                        "\n",
                        "▁आहे\t-4.60313\n",
                        "\n",
                        "▁\t-4.68035\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "with open(\"en_mr_unigram.vocab\", \"r\", encoding=\"utf-8\") as f:\n",
                "    for i in range(10):\n",
                "        print(f.readline())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
